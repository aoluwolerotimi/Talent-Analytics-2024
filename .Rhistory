# sort by examiner_id and quarter
applications <- applications %>%
arrange(examiner_id, quarter)
# Creating seperation and au indicator
# sort by examiner_id and quarter
# applications <- applications %>%
#   arrange(examiner_id, quarter)
applications <- applications %>%
ungroup() %>%
arrange(examiner_id, quarter)
# Creating seperation and au indicator
# sort by examiner_id and quarter
# applications <- applications %>%
#   ungroup() %>%
#   arrange(examiner_id, quarter)
write_feather(applications, paste0(data_path,"app_data_coded_plus.feather"))
# applications_selected <- applications %>%
#   select(
#     application_number,
#     examiner_id,
#     examiner_name_first,
#     examiner_name_middle,
#     examiner_name_last,
#     tc,
#     quarter,
#     new_applications,
#     ISSUED_applications,
#     abn_applications,
#     PEN_applications,
#     examiner_art_unit,
#     women_in_art_unit,
#     Asian_in_art_unit,
#     Black_in_art_unit,
#     Other_in_art_unit,
#     White_in_art_unit,
#     ends_with(".x")  # Select columns that end with '_x'
#   ) %>%
#   rename_with(~ str_remove(., ".x"), ends_with(".x"))  # Remove the '_x' suffix
# Creating seperation and au indicator
# sort by examiner_id and quarter
# applications <- applications %>%
#   ungroup() %>%
#   arrange(examiner_id, quarter)
# write_feather(applications, paste0(data_path,"app_data_coded_plus.feather")) # just in case i need to come back to this stage
applications_selected <- applications %>%
select(
examiner_id,
quarter,
examiner_name_first,
examiner_name_middle,
examiner_name_last,
tc,
new_applications,
iss_applications,
abn_applications,
pen_applications,
examiner_art_unit,
art_unit_hc,
women_in_art_unit,
Asian_in_art_unit,
Black_in_art_unit,
Other_in_art_unit,
White_in_art_unit,
ends_with(".x")  # Select columns that end with '_x'
) %>%
rename_with(~ str_remove(., ".x"), ends_with(".x"))  # Remove the '_x' suffix
# Subsetting data to only include the columns we need
# sort by examiner_id and quarter
# applications <- applications %>%
#   ungroup() %>%
#   arrange(examiner_id, quarter)
# write_feather(applications, paste0(data_path,"app_data_coded_plus.feather")) # just in case i need to come back to this stage
# applications_selected <- applications %>%
#   select(
#     examiner_id,
#     quarter,
#     examiner_name_first,
#     examiner_name_middle,
#     examiner_name_last,
#     tc,
#     new_applications,
#     iss_applications,
#     abn_applications,
#     pen_applications,
#     examiner_art_unit,
#     art_unit_hc,
#     women_in_art_unit,
#     Asian_in_art_unit,
#     Black_in_art_unit,
#     Other_in_art_unit,
#     White_in_art_unit,
#     ends_with(".x")  # Select columns that end with '_x'
#   ) %>%
#   rename_with(~ str_remove(., ".x"), ends_with(".x"))  # Remove the '_x' suffix
View(applications_selected)
# Subsetting data to only include the columns we need
# sort by examiner_id and quarter
# applications <- applications %>%
#   ungroup() %>%
#   arrange(examiner_id, quarter)
# write_feather(applications, paste0(data_path,"app_data_coded_plus.feather")) # just in case i need to come back to this stage
# applications_selected <- applications %>%
#   select(
#     examiner_id,
#     quarter,
#     examiner_name_first,
#     examiner_name_middle,
#     examiner_name_last,
#     tc,
#     new_applications,
#     iss_applications,
#     abn_applications,
#     pen_applications,
#     examiner_art_unit,
#     art_unit_hc,
#     women_in_art_unit,
#     Asian_in_art_unit,
#     Black_in_art_unit,
#     Other_in_art_unit,
#     White_in_art_unit,
#     ends_with(".x")  # Select columns that end with '_x'
#   ) %>%
#   rename_with(~ str_remove(., ".x"), ends_with(".x"))  # Remove the '_x' suffix
# View(applications_selected)
applications_selected <- applications_selected %>%
select(-examiner_name_middle)
# SEPARATION INDICATOR
# need to find each examiner's max quarter
applications_selected %>%
group_by(examiner_id) %>%
mutate(max_quarter = max(quarter))
# SEPARATION INDICATOR
# need to find each examiner's max quarter
# applications_selected %>%
#   group_by(examiner_id) %>%
#   mutate(max_quarter = max(quarter))
# and need to find overall max quarter in the dataset
applications_selected %>%
group_by(quarter) %>%
summarise(n = n_distinct(examiner_id)) %>%
arrange(desc(quarter)) %>% head(5)
# SEPARATION INDICATOR
# need to find each examiner's max quarter
# applications_selected %>%
#   group_by(examiner_id) %>%
#   mutate(max_quarter = max(quarter))
# and need to find overall max quarter in the dataset
# applications_selected %>%
#   group_by(quarter) %>%
#   summarise(n = n_distinct(examiner_id)) %>%
#   arrange(desc(quarter)) %>% head(5)
# 2017/2 is the max quarter in the dataset. but only 68 left over there so using 2017/1 instead
# could have been a data collection issue bc that's a huge drop
overall_max_quarter <- "2017/1"
# Create the separation_indicator
applications_selected <- applications_selected %>%
group_by(examiner_id) %>%
mutate(max_quarter_examiner = max(quarter)) %>%
ungroup() %>%
mutate(separation_indicator = if_else(max_quarter_examiner < overall_max_quarter, 1, 0))
applications_selected
# SEPARATION INDICATOR
# need to find each examiner's max quarter
# applications_selected %>%
#   group_by(examiner_id) %>%
#   mutate(max_quarter = max(quarter))
# and need to find overall max quarter in the dataset
# applications_selected %>%
#   group_by(quarter) %>%
#   summarise(n = n_distinct(examiner_id)) %>%
#   arrange(desc(quarter)) %>% head(5)
# 2017/2 is the max quarter in the dataset. but only 68 left over there so using 2017/1 instead
# could have been a data collection issue bc that's a huge drop
overall_max_quarter <- "2017/1"
# # Create the separation_indicator
# applications_selected <- applications_selected %>%
#   group_by(examiner_id) %>%
#   mutate(max_quarter_examiner = max(quarter)) %>%
#   ungroup() %>%
#   mutate(separation_indicator = if_else(max_quarter_examiner < overall_max_quarter, 1, 0))
applications_selected <- applications_selected %>%
select(-separation_indicator)
# SEPARATION INDICATOR
# need to find each examiner's max quarter
# applications_selected %>%
#   group_by(examiner_id) %>%
#   mutate(max_quarter = max(quarter))
# and need to find overall max quarter in the dataset
# applications_selected %>%
#   group_by(quarter) %>%
#   summarise(n = n_distinct(examiner_id)) %>%
#   arrange(desc(quarter)) %>% head(5)
# 2017/2 is the max quarter in the dataset. but only 68 left over there so using 2017/1 instead
# could have been a data collection issue bc that's a huge drop
# overall_max_quarter <- "2017/1"
applications_selected <- applications_selected %>%
group_by(examiner_id) %>%
mutate(max_quarter = max(quarter, na.rm = TRUE)) %>%
ungroup() %>%
mutate(separation_indicator = case_when(
quarter < max_quarter ~ 0,
quarter == max_quarter & quarter < overall_max_quarter ~ 1,
TRUE ~ 0
))
# SEPARATION INDICATOR
# need to find each examiner's max quarter
# applications_selected %>%
#   group_by(examiner_id) %>%
#   mutate(max_quarter = max(quarter))
# and need to find overall max quarter in the dataset
# applications_selected %>%
#   group_by(quarter) %>%
#   summarise(n = n_distinct(examiner_id)) %>%
#   arrange(desc(quarter)) %>% head(5)
# 2017/2 is the max quarter in the dataset. but only 68 left over there so using 2017/1 instead
# could have been a data collection issue bc that's a huge drop
# overall_max_quarter <- "2017/1"
# applications_selected <- applications_selected %>%
#   group_by(examiner_id) %>%
#   mutate(max_quarter = max(quarter, na.rm = TRUE)) %>%
#   ungroup() %>%
#   mutate(separation_indicator = case_when(
#     quarter < max_quarter ~ 0,
#     quarter == max_quarter & quarter < overall_max_quarter ~ 1,
#     TRUE ~ 0
#   ))
print(unique(applications_selected$separation_indicator))
applications_selected <- applications_selected %>%
group_by(examiner_id) %>%
arrange(examiner_id, quarter) %>%
mutate(au_move = if_else(examiner_art_unit != lag(examiner_art_unit, default = first(examiner_art_unit)), 1, 0)) %>%
ungroup()
applications_selected %>%
summarise_all(~ sum(is.na(.)))
applications %>%
summarise_all(~ sum(is.na(.)))
# applications_selected %>%
#   summarise_all(~ sum(is.na(.)))
# a bunch of examiner IDs are N/A but the quarter and first and last name are not so that is WEIRD
write_feather(applications_selected, paste0(data_path,"app_data_w_indicators.feather"))
# applications_selected %>%
#   summarise_all(~ sum(is.na(.)))
# a bunch of examiner IDs are N/A but the quarter and first and last name are not so that is WEIRD
# write_feather(applications_selected, paste0(data_path,"app_data_w_indicators.feather"))
glimpse(applications_selected)
knitr::opts_chunk$set(echo = TRUE)
data_path <- "/Users/aoluwolerotimi/Datasets/"
applications <- read_feather(paste0(data_path,"app_data_w_indicators.feather"))
library(arrow)
library(tidyverse)
library(dplyr)
library(lubridate)
applications <- read_feather(paste0(data_path,"app_data_w_indicators.feather"))
View(applications)
colnames(applications)
examiners <- pdata.frame(applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# library(arrow)
# library(tidyverse)
# library(dplyr)
# library(lubridate)
library(plm)
examiners <- pdata.frame(applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# Duplicates found in data frame, dealing with those
table(index(examiners), useNA = "ifany")
# Duplicates found in data frame, dealing with those
# table(index(examiners), useNA = "ifany")
applications %>%
summarise_all(~ sum(is.na(.)))
# Duplicates found in data frame, dealing with those
# table(index(examiners), useNA = "ifany")
# applications %>%
#   summarise_all(~ sum(is.na(.)))
# 9229 N/As in examiner_id. will need to go back and investigate, but for now focusing on learning objective of creating panel data regressions
# so I will drop those rows
applications <- applications[!is.na(applications$examiner_id) & !is.na(applications$quarter), ]
examiners <- pdata.frame(applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# Now dealing with duplicates
dup_example <- applications[applications$examiner_id == 59074 & applications$quarter == "2000/1", ]
print(dup_example)
# Now dealing with duplicates
dup_example <- applications[applications$examiner_id == 59030 & applications$quarter == "2009/3", ]
print(dup_example)
cleaned_applications <- applications %>%
group_by(examiner_id, quarter) %>%
arrange(desc(separation_indicator), desc(au_move)) %>% # Prioritize rows with 1s
filter(if(any(separation_indicator == 1 | au_move == 1)) {
separation_indicator == 1 | au_move == 1
} else {
row_number() == 1
}) %>%
ungroup()
examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
table(index(examiners), useNA = "ifany")
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter == "2001/2", ]
print(dup_example)
# dup_example <- applications[applications$examiner_id == 59054 & applications$quarter == "2001/2", ]
# print(dup_example)
# hmm, for the same quarter seeing AU move of 0 and AU move of 1. definitely have to revisit process of creating panel dataset in Ex 2
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter %in% c("2001/1", "2001/2"), ]
print(dup_example)
cleaned_applications <- applications %>%
select(-au_move) %>% # Drop the au_move column
group_by(examiner_id, quarter) %>%
arrange(desc(separation_indicator)) %>% # Prioritize rows with separation_indicator = 1
filter(if (any(separation_indicator == 1)) {
row_number() == which(separation_indicator == 1)[1] # Keep the first row with separation_indicator = 1
} else {
row_number() == 1 # If no 1s, keep the first row
}) %>%
ungroup()
examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
table(index(examiners), useNA = "ifany")
# examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# table(index(examiners), useNA = "ifany")
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter == "2000/4", ]
print(dup_example)
# examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# table(index(examiners), useNA = "ifany")
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter%in% c("2001/3", "2001/4", "2002/1", "2002/2"), ]
print(dup_example)
# examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# table(index(examiners), useNA = "ifany")
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter%in% c("2002/1"), ]
print(dup_example)
# dup_example <- applications[applications$examiner_id == 59054 & applications$quarter == "2001/2", ]
# print(dup_example)
# hmm, for the same quarter seeing AU move of 0 and AU move of 1. definitely have to revisit process of creating panel dataset in Ex 2
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter == "2009/3", ]
print(dup_example)
# Okay, for the same quarter, there are different art units recorded. to keep moving with the exercise, I will focus just on the separation_indicator
# dup_example <- applications[applications$examiner_id == 59054 & applications$quarter == "2001/2", ]
# print(dup_example)
# hmm, for the same quarter seeing AU move of 0 and AU move of 1. definitely have to revisit process of creating panel dataset in Ex 2
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter == "2002/1", ]
print(dup_example)
# Okay, for the same quarter, there are different art units recorded. to keep moving with the exercise, I will focus just on the separation_indicator
# examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
table(index(examiners), useNA = "ifany")
# dup_example <- applications[applications$examiner_id == 59054 & applications$quarter%in% c("2002/1"), ]
# print(dup_example)
# examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# table(index(examiners), useNA = "ifany")
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter%in% c("2001/3"), ]
# print(dup_example)
# examiners <- pdata.frame(cleaned_applications, index = c("examiner_id", "quarter"), drop.index = FALSE)
# table(index(examiners), useNA = "ifany")
dup_example <- applications[applications$examiner_id == 59054 & applications$quarter%in% c("2001/3"), ]
print(dup_example)
colnames(examiners)
#colnames(examiners)
View(examiners)
#colnames(examiners)
# View(examiners)
examiners %>%
summarise_all(~ sum(is.na(.)))
#colnames(examiners)
# View(examiners)
# examiners %>%
#   summarise_all(~ sum(is.na(.)))
# gender and women in art unit had a bunch of NA values so excluding them for this exercise
print(unique(examiners$examiner_art_unit))
# Usual logistic regression methods. No specific consideration to being panel data
library(caret)
library(nnet)
# Convert 'race' to a factor since it's categorical
examiners$race <- as.factor(examiners$race)
# Creating dummy variables for 'race'
examiners <- dummyVars("~ race", data = examiners) %>%
predict(newdata = examiners) %>%
as.data.frame() %>%
bind_cols(examiners, .)
# Splitting the data into training and testing sets
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(examiners$separation_indicator, p = .8,
list = FALSE,
times = 1)
trainData <- examiners[trainIndex, ]
testData <- examiners[-trainIndex, ]
# Build the model - logistic regression
model1 <- multinom(separation_indicator ~ race.Asian + race.Black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit, data = trainData)
# Build the model - logistic regression
model1 <- multinom(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit, data = trainData)
# Summary of the model
summary(model1)
# Usual logistic regression methods. No specific consideration to being panel data
# library(caret)
# library(nnet)
# # Convert 'race' to a factor since it's categorical
# examiners$race <- as.factor(examiners$race)
#
# # Creating dummy variables for 'race'
# examiners <- dummyVars("~ race", data = examiners) %>%
#              predict(newdata = examiners) %>%
#              as.data.frame() %>%
#              bind_cols(examiners, .)
# Converting separation_indicator to a factor
examiners$separation_indicator <- as.factor(examiners$separation_indicator)
# Splitting the data into training and testing sets
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(examiners$separation_indicator, p = .8,
list = FALSE,
times = 1)
trainData <- examiners[trainIndex, ]
testData <- examiners[-trainIndex, ]
# Build the model - logistic regression
model1 <- glm(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit, family = binomial, data = trainData)
# Summary of the model
summary(model1)
# Trying for a fixed effects model
model2 <- plm(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit,
data = trainData, model = "within", family = binomial())
# Trying for a fixed effects model
# plm package requires the binary variables to be numeric rather than as factors
trainData$race.Asian <- as.numeric(trainData$race.Asian)
trainData$race.black <- as.numeric(trainData$race.black)
trainData$race.Hispanic <- as.numeric(trainData$race.Hispanic)
trainData$race.other <- as.numeric(trainData$race.other)
trainData$separation_indicator <- as.numeric(trainData$separation_indicator)
model2 <- plm(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit,
data = trainData, model = "within", family = binomial())
# Summary of the model
summary(model2)
vif(model2)
library(car)
vif(model2)
View(cleaned_applications)
# Filter the dataset to keep only the rows where 'quarter' equals 'max_quarter'
reg_dataset <- cleaned_applications %>%
group_by(examiner_id) %>%
filter(quarter == max_quarter) %>%
ungroup()
View(reg_dataset)
# Convert 'race' to a factor since it's categorical
reg_dataset$race <- as.factor(reg_dataset$race)
# Creating dummy variables for 'race'
reg_dataset <- dummyVars("~ race", data = reg_dataset) %>%
predict(newdata = reg_dataset) %>%
as.data.frame() %>%
bind_cols(reg_dataset, .)
# Splitting the data into training and testing sets
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(reg_dataset$separation_indicator, p = .8,
list = FALSE,
times = 1)
trainData <- reg_dataset[trainIndex, ]
testData <- reg_dataset[-trainIndex, ]
# Build the model - logistic regression
model3 <- glm(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit, family = binomial, data = trainData)
# Summary of the model
summary(model3)
reg_dataset$separation_indicator <- as.factor(reg_dataset$separation_indicator)
# Build the model - logistic regression
model3 <- glm(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit, family = binomial, data = trainData)
# Summary of the model
summary(model3)
vif(model3)
trainData$separation_indicator <- as.factor(trainData$separation_indicator)
# Build the model - logistic regression
model3 <- glm(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit, family = binomial, data = trainData)
# Summary of the model
summary(model3)
vif(model3)
# Predict on test data
testData$separation_indicator <- as.factor(testData$separation_indicator)
predictions <- predict(model3, testData)
# Evaluate the model
confusionMatrix(predictions, testData$separation_indicator)
# Build the model - logistic regression
model3 <- glm(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + iss_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit, family = binomial, data = trainData)
# Summary of the model
summary(model3)
# trying without issued applications variable
# Build the model - logistic regression
model4 <- glm(separation_indicator ~ race.Asian + race.black + race.Hispanic + race.other + tenure_days + new_applications + abn_applications + pen_applications + art_unit_hc + Asian_in_art_unit + Black_in_art_unit + White_in_art_unit + Other_in_art_unit, family = binomial, data = trainData)
# Summary of the model
summary(model4)
# Predict on test data
predictions <- predict(model3, testData)
# Evaluate the model
confusionMatrix(predictions, testData$separation_indicator)
View(testData)
View(trainData)
# Convert predicted probabilities to class labels
# Assuming your model predicts probabilities for class '1'
predicted_probabilities <- predict(model3, testData, type = "response")
predicted_labels <- ifelse(predicted_probabilities > 0.5, 1, 0)
# Convert to factor if not already
predicted_labels <- factor(predicted_labels, levels = c(0, 1))
actual_labels <- factor(testData$separation_indicator, levels = c(0, 1))
# Evaluate the model using confusion matrix
confusionMatrix(predicted_labels, actual_labels)
# get unique values for separation_indicator in reg_dataset
unique(reg_dataset$separation_indicator)
# Convert predicted probabilities to class labels
# Assuming your model predicts probabilities for class '1'
predicted_probabilities <- predict(model3, testData, type = "response")
predicted_labels <- ifelse(predicted_probabilities > 0.5, 1, 0)
# Convert to factor if not already
# Ensure '1' is the first level in the factor
predicted_labels <- factor(predicted_labels, levels = c(1, 0))
actual_labels <- factor(testData$separation_indicator, levels = c(1, 0))
# Evaluate the model using confusion matrix
confusionMatrix(predicted_labels, actual_labels)
library(pROC)
# Create the ROC curve
roc_curve <- roc(testData$separation_indicator, predicted_probabilities)
# Plot the ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue")
abline(a = 0, b = 1, lty = 2, col = "red")  # Adds a diagonal reference line
# Adding AUC (Area Under Curve) to the plot
auc(roc_curve)
