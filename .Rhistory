) %>%
ungroup()
#distinct uspc_class and uspc_subclass by quarter
applications <- applications %>%
group_by(examiner_id, quarter) %>%
mutate(
num_classes = n_distinct(uspc_class),
num_subclasses = n_distinct(uspc_subclass)
) %>%
ungroup()
# get the process time
applications <- applications %>%
mutate(
patent_issue_date = as.Date(patent_issue_date),
abandon_date = as.Date(abandon_date),
processing_time = case_when(
disposal_type == "ISS" ~ as.numeric(patent_issue_date - filing_date, units = "days"),
disposal_type == "ABN" ~ as.numeric(abandon_date - filing_date, units = "days"),
TRUE ~ 0
)
)
applications <- applications %>%
mutate(
iss_time = ifelse(disposal_type == "ISS", processing_time, NA),
abn_time = ifelse(disposal_type == "ABN", processing_time, NA)
)
# Computing averages within the same dataframe
applications <- applications %>%
group_by(examiner_id) %>%
mutate(
avg_processing = mean(processing_time, na.rm = TRUE),
avg_ISS_processing = mean(iss_time, na.rm = TRUE),
avg_ABN_processing = mean(abn_time, na.rm = TRUE)
) %>%
ungroup()
columns_to_exclude <- c(
"examiner_art_unit", "examiner_art_unit_num",
"women_in_art_unit"
) # Due to a high number of missing vlaue in the gender value, the quality of the women_in_art_unit is poor, thus excluded
df <- applications[, !(names(applications) %in% columns_to_exclude)]
colSums(is.na(df))
#drop the na examiner_id rows
df <- subset(df, !is.na(examiner_id))
#aggregate to quarter
quarter_df <- df %>%
group_by(examiner_id) %>%
distinct(quarter, .keep_all = TRUE) %>%
select(examiner_id, quarter, latest_date, separation_indicator, ISSUED_applications, PEN_applications, abn_applications, gender, race, tenure_days, au_moves, tc_count, num_classes, num_subclasses, avg_processing, avg_ISS_processing, avg_ABN_processing, TC_1700_count, TC_1600_count, TC_2100_count, TC_2400_count) %>%
arrange(examiner_id, quarter)
#collapse to individual observation
collapsed_df <- quarter_df %>%
group_by(examiner_id) %>%
summarize(
gender = first(gender),
race = first(race),
tenure_days = first(tenure_days),
ISSUED_applications = sum(ISSUED_applications),
abandoned_applications = sum(abn_applications),
au_moves = sum(au_moves),
tc_count = first(tc_count),
PEN_applications = sum(PEN_applications) / n(),
separation_indicator = max(separation_indicator),
num_classes = sum(num_classes),
num_subclasses = sum(num_subclasses),
avg_processing = first(avg_processing),
avg_ISS_processing = first(avg_ISS_processing),
avg_ABN_processing = first(avg_ABN_processing),
TC_1700_count = first(TC_1700_count),
TC_1600_count = first(TC_1600_count),
TC_2100_count = first(TC_2100_count),
TC_2400_count = first(TC_2400_count)
)
#append NA with 'unknown'
collapsed_df <- collapsed_df %>%
mutate(gender = ifelse(is.na(gender), "unknown", gender))
colSums(is.na(collapsed_df))
#Fill NA to 0
collapsed_df <- collapsed_df %>%
mutate_all(~ifelse(is.na(.), 0, .))
summary(collapsed_df)
collapsed_df$separation_indicator <- factor(make.names(as.character(collapsed_df$separation_indicator)))
collapsed_df$gender <- as.factor(collapsed_df$gender)
collapsed_df$race <- as.factor(collapsed_df$race)
#Train Split
library(caret)
set.seed(123)
splitIndex <- createDataPartition(collapsed_df$separation_indicator, p = .75, list = FALSE)
train_data <- collapsed_df[splitIndex,]
test_data <- collapsed_df[-splitIndex,]
indexes <- sample(1:nrow(collapsed_df), size = 0.75 * nrow(collapsed_df))
train_data_lm <- collapsed_df[indexes, ]
test_data_lm <- collapsed_df[-indexes, ]
train_control <- trainControl(method = "cv", number = 10)
#avg_processing as outcome
model <- train(avg_processing ~ tenure_days + num_classes + num_subclasses +
ISSUED_applications + au_moves +  + gender + race +
gender * tenure_days + TC_1700_count + TC_1600_count + TC_2100_count                + TC_2400_count + race * tenure_days,
data = train_data_lm,
method = "lm",
trControl = train_control)
#avg_ISS_processing as outcome
model2 <- train(avg_ISS_processing ~ tenure_days + num_classes + num_subclasses+
ISSUED_applications + au_moves + tc_count + gender + race +
gender * tenure_days + TC_1700_count + TC_1600_count +                             TC_2100_count + TC_2400_count + race * tenure_days,
data = train_data_lm,
method = "lm",
trControl = train_control)
#avg_ABN_processing as outcome
model3 <- train(avg_ABN_processing ~ tenure_days + num_classes + num_subclasses+
ISSUED_applications + au_moves + tc_count + gender + race + +                      TC_1700_count + TC_1600_count + TC_2100_count + TC_2400_count +
gender * tenure_days + race * tenure_days,
data = train_data_lm,
method = "lm",
trControl = train_control)
summary(model)
library(arrow)
library(tidyverse)
library(lubridate)
# data_path <- "C:/Users/csg20/Downloads/"
# applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
data_path <- "/Users/aoluwolerotimi/Datasets/" # AO Changed file path
applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
columns_with_x_suffix <- grep("\\.x$", names(applications), value = TRUE)
names(applications)[names(applications) %in% columns_with_x_suffix] <- sub("\\.x$", '', columns_with_x_suffix)
applications <- applications %>% select(-ends_with(".y"))
library(arrow)
library(tidyverse)
library(lubridate)
# data_path <- "C:/Users/csg20/Downloads/"
# applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
data_path <- "/Users/aoluwolerotimi/Datasets/" # AO Changed file path
applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
columns_with_x_suffix <- grep("\\.x$", names(applications), value = TRUE)
names(applications)[names(applications) %in% columns_with_x_suffix] <- sub("\\.x$", '', columns_with_x_suffix)
applications <- applications %>% select(-ends_with(".y"))
max_quarter <- "2017/1"
applications <- applications %>%
filter(quarter <= max_quarter)
max_quarter <- "2017/1"
applications <- applications %>%
filter(quarter <= max_quarter)
library(arrow)
library(tidyverse)
library(lubridate)
# data_path <- "C:/Users/csg20/Downloads/"
# applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
data_path <- "/Users/aoluwolerotimi/Datasets/" # AO Changed file path
applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
columns_with_x_suffix <- grep("\\.x$", names(applications), value = TRUE)
names(applications)[names(applications) %in% columns_with_x_suffix] <- sub("\\.x$", '', columns_with_x_suffix)
applications <- applications %>% select(-ends_with(".y"))
#quarter
applications <- applications %>%
mutate(
quarter = paste0(year(filing_date), "/", quarter(filing_date)),
)
# Aggregate applications by quarter and examiner
applications <- applications %>%
group_by(quarter, examiner_id) %>%
mutate(new_applications = n_distinct(application_number)) %>%
ungroup()
applications <- applications %>%
group_by(quarter, examiner_id) %>%
mutate(ISSUED_applications = sum(disposal_type == "ISS" & !duplicated(application_number)))
applications <- applications %>%
group_by(quarter, examiner_id) %>%
mutate(abn_applications = sum(disposal_type == "ABN" & !duplicated(application_number)))
applications <- applications %>%
group_by(quarter, examiner_id) %>%
mutate(PEN_applications = sum(disposal_type == "PEND" & !duplicated(application_number)))
applications <- applications %>%
group_by(quarter,examiner_art_unit) %>%
mutate(examiner_art_unit_num =  n_distinct(examiner_id))%>%
ungroup()
max_quarter <- "2017/1"
applications <- applications %>%
filter(quarter <= max_quarter)
# separation_indicator
applications <- applications %>%
group_by(examiner_id) %>%
mutate(max_quarter_examiner = max(quarter)) %>%
ungroup() %>%
mutate(separation_indicator = if_else(max_quarter_examiner < max_quarter, 1, 0))
# to delete lastest_date that is beyond the max_quarter
max_year <- "2018"
applications <- applications %>%
mutate(latest_date = as.Date(latest_date),
year_latest_date = year(latest_date)) %>%
filter(year_latest_date <= max_year) %>%
select(-year_latest_date)
#au_move_indicator
applications <- applications %>%
group_by(examiner_id) %>%
mutate(au_move_indicator = if_else(examiner_art_unit != lag(examiner_art_unit), 1, 0)) %>%
ungroup()
applications <- applications %>%
mutate(au_move_indicator = if_else(is.na(au_move_indicator), 0, au_move_indicator))
applications <- applications %>%
mutate(TC_1700 = if_else(tc == 1700, 1, 0),
TC_1600 = if_else(tc == 1600, 1, 0),
TC_2100 = if_else(tc == 2100, 1, 0),
TC_2400 = if_else(tc == 2400, 1, 0))
applications_summary <- applications %>%
group_by(examiner_id) %>%
summarise(
TC_1700_count = sum(TC_1700, na.rm = TRUE),
TC_1600_count = sum(TC_1600, na.rm = TRUE),
TC_2100_count = sum(TC_2100, na.rm = TRUE),
TC_2400_count = sum(TC_2400, na.rm = TRUE),
.groups = 'drop' # This drops the grouping structure, not required but cleaner
)
# Step 2: Join this summary back to the original applications dataframe
applications <- applications %>%
left_join(applications_summary, by = "examiner_id")
# get the count of au_moves by quarter
applications <- applications %>%
group_by(examiner_id, quarter) %>%
mutate(
au_moves = sum(au_move_indicator)
) %>%
ungroup()
#distinct uspc_class and uspc_subclass by quarter
applications <- applications %>%
group_by(examiner_id, quarter) %>%
mutate(
num_classes = n_distinct(uspc_class),
num_subclasses = n_distinct(uspc_subclass)
) %>%
ungroup()
# get the process time
applications <- applications %>%
mutate(
patent_issue_date = as.Date(patent_issue_date),
abandon_date = as.Date(abandon_date),
processing_time = case_when(
disposal_type == "ISS" ~ as.numeric(patent_issue_date - filing_date, units = "days"),
disposal_type == "ABN" ~ as.numeric(abandon_date - filing_date, units = "days"),
TRUE ~ 0
)
)
applications <- applications %>%
mutate(
iss_time = ifelse(disposal_type == "ISS", processing_time, NA),
abn_time = ifelse(disposal_type == "ABN", processing_time, NA)
)
# Computing averages within the same dataframe
applications <- applications %>%
group_by(examiner_id) %>%
mutate(
avg_processing = mean(processing_time, na.rm = TRUE),
avg_ISS_processing = mean(iss_time, na.rm = TRUE),
avg_ABN_processing = mean(abn_time, na.rm = TRUE)
) %>%
ungroup()
columns_to_exclude <- c(
"examiner_art_unit", "examiner_art_unit_num",
"women_in_art_unit"
) # Due to a high number of missing vlaue in the gender value, the quality of the women_in_art_unit is poor, thus excluded
df <- applications[, !(names(applications) %in% columns_to_exclude)]
colSums(is.na(df))
#drop the na examiner_id rows
df <- subset(df, !is.na(examiner_id))
#aggregate to quarter
quarter_df <- df %>%
group_by(examiner_id) %>%
distinct(quarter, .keep_all = TRUE) %>%
select(examiner_id, quarter, latest_date, separation_indicator, ISSUED_applications, PEN_applications, abn_applications, gender, race, tenure_days, au_moves, num_classes, num_subclasses, avg_processing, avg_ISS_processing, avg_ABN_processing, TC_1700_count, TC_1600_count, TC_2100_count, TC_2400_count) %>%
arrange(examiner_id, quarter)
#collapse to individual observation
collapsed_df <- quarter_df %>%
group_by(examiner_id) %>%
summarize(
gender = first(gender),
race = first(race),
tenure_days = first(tenure_days),
ISSUED_applications = sum(ISSUED_applications),
abandoned_applications = sum(abn_applications),
au_moves = sum(au_moves),
= first(),
#drop the na examiner_id rows
df <- subset(df, !is.na(examiner_id))
#aggregate to quarter
quarter_df <- df %>%
group_by(examiner_id) %>%
distinct(quarter, .keep_all = TRUE) %>%
select(examiner_id, quarter, latest_date, separation_indicator, ISSUED_applications, PEN_applications, abn_applications, gender, race, tenure_days, au_moves, num_classes, num_subclasses, avg_processing, avg_ISS_processing, avg_ABN_processing, TC_1700_count, TC_1600_count, TC_2100_count, TC_2400_count) %>%
arrange(examiner_id, quarter)
#collapse to individual observation
collapsed_df <- quarter_df %>%
group_by(examiner_id) %>%
summarize(
gender = first(gender),
race = first(race),
tenure_days = first(tenure_days),
ISSUED_applications = sum(ISSUED_applications),
abandoned_applications = sum(abn_applications),
au_moves = sum(au_moves),
= first(),
library(arrow)
library(tidyverse)
library(lubridate)
# data_path <- "C:/Users/csg20/Downloads/"
# applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
data_path <- "/Users/aoluwolerotimi/Datasets/" # AO Changed file path
applications <- read_feather(paste0(data_path,"app_data_starter_coded.feather"))
columns_with_x_suffix <- grep("\\.x$", names(applications), value = TRUE)
names(applications)[names(applications) %in% columns_with_x_suffix] <- sub("\\.x$", '', columns_with_x_suffix)
applications <- applications %>% select(-ends_with(".y"))
#quarter
applications <- applications %>%
mutate(
quarter = paste0(year(filing_date), "/", quarter(filing_date)),
)
# Aggregate applications by quarter and examiner
applications <- applications %>%
group_by(quarter, examiner_id) %>%
mutate(new_applications = n_distinct(application_number)) %>%
ungroup()
applications <- applications %>%
group_by(quarter, examiner_id) %>%
mutate(ISSUED_applications = sum(disposal_type == "ISS" & !duplicated(application_number)))
applications <- applications %>%
group_by(quarter, examiner_id) %>%
mutate(abn_applications = sum(disposal_type == "ABN" & !duplicated(application_number)))
applications <- applications %>%
group_by(quarter, examiner_id) %>%
mutate(PEN_applications = sum(disposal_type == "PEND" & !duplicated(application_number)))
applications <- applications %>%
group_by(quarter,examiner_art_unit) %>%
mutate(examiner_art_unit_num =  n_distinct(examiner_id))%>%
ungroup()
max_quarter <- "2017/1"
applications <- applications %>%
filter(quarter <= max_quarter)
# separation_indicator
applications <- applications %>%
group_by(examiner_id) %>%
mutate(max_quarter_examiner = max(quarter)) %>%
ungroup() %>%
mutate(separation_indicator = if_else(max_quarter_examiner < max_quarter, 1, 0))
# to delete lastest_date that is beyond the max_quarter
max_year <- "2018"
applications <- applications %>%
mutate(latest_date = as.Date(latest_date),
year_latest_date = year(latest_date)) %>%
filter(year_latest_date <= max_year) %>%
select(-year_latest_date)
#au_move_indicator
applications <- applications %>%
group_by(examiner_id) %>%
mutate(au_move_indicator = if_else(examiner_art_unit != lag(examiner_art_unit), 1, 0)) %>%
ungroup()
applications <- applications %>%
mutate(au_move_indicator = if_else(is.na(au_move_indicator), 0, au_move_indicator))
applications <- applications %>%
mutate(TC_1700 = if_else(tc == 1700, 1, 0),
TC_1600 = if_else(tc == 1600, 1, 0),
TC_2100 = if_else(tc == 2100, 1, 0),
TC_2400 = if_else(tc == 2400, 1, 0))
applications_summary <- applications %>%
group_by(examiner_id) %>%
summarise(
TC_1700_count = sum(TC_1700, na.rm = TRUE),
TC_1600_count = sum(TC_1600, na.rm = TRUE),
TC_2100_count = sum(TC_2100, na.rm = TRUE),
TC_2400_count = sum(TC_2400, na.rm = TRUE),
.groups = 'drop' # This drops the grouping structure, not required but cleaner
)
# Step 2: Join this summary back to the original applications dataframe
applications <- applications %>%
left_join(applications_summary, by = "examiner_id")
# get the count of au_moves by quarter
applications <- applications %>%
group_by(examiner_id, quarter) %>%
mutate(
au_moves = sum(au_move_indicator)
) %>%
ungroup()
#distinct uspc_class and uspc_subclass by quarter
applications <- applications %>%
group_by(examiner_id, quarter) %>%
mutate(
num_classes = n_distinct(uspc_class),
num_subclasses = n_distinct(uspc_subclass)
) %>%
ungroup()
# get the process time
applications <- applications %>%
mutate(
patent_issue_date = as.Date(patent_issue_date),
abandon_date = as.Date(abandon_date),
processing_time = case_when(
disposal_type == "ISS" ~ as.numeric(patent_issue_date - filing_date, units = "days"),
disposal_type == "ABN" ~ as.numeric(abandon_date - filing_date, units = "days"),
TRUE ~ 0
)
)
applications <- applications %>%
mutate(
iss_time = ifelse(disposal_type == "ISS", processing_time, NA),
abn_time = ifelse(disposal_type == "ABN", processing_time, NA)
)
# Computing averages within the same dataframe
applications <- applications %>%
group_by(examiner_id) %>%
mutate(
avg_processing = mean(processing_time, na.rm = TRUE),
avg_ISS_processing = mean(iss_time, na.rm = TRUE),
avg_ABN_processing = mean(abn_time, na.rm = TRUE)
) %>%
ungroup()
columns_to_exclude <- c(
"examiner_art_unit", "examiner_art_unit_num",
"women_in_art_unit"
) # Due to a high number of missing vlaue in the gender value, the quality of the women_in_art_unit is poor, thus excluded
df <- applications[, !(names(applications) %in% columns_to_exclude)]
colSums(is.na(df))
#drop the na examiner_id rows
df <- subset(df, !is.na(examiner_id))
#aggregate to quarter
quarter_df <- df %>%
group_by(examiner_id) %>%
distinct(quarter, .keep_all = TRUE) %>%
select(examiner_id, quarter, latest_date, separation_indicator, ISSUED_applications, PEN_applications, abn_applications, gender, race, tenure_days, au_moves, num_classes, num_subclasses, avg_processing, avg_ISS_processing, avg_ABN_processing, TC_1700_count, TC_1600_count, TC_2100_count, TC_2400_count) %>%
arrange(examiner_id, quarter)
#collapse to individual observation
collapsed_df <- quarter_df %>%
group_by(examiner_id) %>%
summarize(
gender = first(gender),
race = first(race),
tenure_days = first(tenure_days),
ISSUED_applications = sum(ISSUED_applications),
abandoned_applications = sum(abn_applications),
au_moves = sum(au_moves),
= first(),
#collapse to individual observation
collapsed_df <- quarter_df %>%
group_by(examiner_id) %>%
summarize(
gender = first(gender),
race = first(race),
tenure_days = first(tenure_days),
ISSUED_applications = sum(ISSUED_applications),
abandoned_applications = sum(abn_applications),
au_moves = sum(au_moves),
= first(),
#collapse to individual observation
collapsed_df <- quarter_df %>%
group_by(examiner_id) %>%
summarize(
gender = first(gender),
race = first(race),
tenure_days = first(tenure_days),
ISSUED_applications = sum(ISSUED_applications),
abandoned_applications = sum(abn_applications),
au_moves = sum(au_moves),
PEN_applications = sum(PEN_applications) / n(),
separation_indicator = max(separation_indicator),
num_classes = sum(num_classes),
num_subclasses = sum(num_subclasses),
avg_processing = first(avg_processing),
avg_ISS_processing = first(avg_ISS_processing),
avg_ABN_processing = first(avg_ABN_processing),
TC_1700_count = first(TC_1700_count),
TC_1600_count = first(TC_1600_count),
TC_2100_count = first(TC_2100_count),
TC_2400_count = first(TC_2400_count)
)
#append NA with 'unknown'
collapsed_df <- collapsed_df %>%
mutate(gender = ifelse(is.na(gender), "unknown", gender))
colSums(is.na(collapsed_df))
#Fill NA to 0
collapsed_df <- collapsed_df %>%
mutate_all(~ifelse(is.na(.), 0, .))
summary(collapsed_df)
collapsed_df$separation_indicator <- factor(make.names(as.character(collapsed_df$separation_indicator)))
collapsed_df$gender <- as.factor(collapsed_df$gender)
collapsed_df$race <- as.factor(collapsed_df$race)
#Train Split
library(caret)
set.seed(123)
splitIndex <- createDataPartition(collapsed_df$separation_indicator, p = .75, list = FALSE)
train_data <- collapsed_df[splitIndex,]
test_data <- collapsed_df[-splitIndex,]
indexes <- sample(1:nrow(collapsed_df), size = 0.75 * nrow(collapsed_df))
train_data_lm <- collapsed_df[indexes, ]
test_data_lm <- collapsed_df[-indexes, ]
train_control <- trainControl(method = "cv", number = 10)
#avg_processing as outcome
model <- train(avg_processing ~ tenure_days + num_classes + num_subclasses +
ISSUED_applications + au_moves + gender + race +
gender * tenure_days + TC_1700_count + TC_1600_count + TC_2100_count                + TC_2400_count + race * tenure_days,
data = train_data_lm,
method = "lm",
trControl = train_control)
#avg_ISS_processing as outcome
model2 <- train(avg_ISS_processing ~ tenure_days + num_classes + num_subclasses+
ISSUED_applications + au_moves + gender + race +
gender * tenure_days + TC_1700_count + TC_1600_count +                             TC_2100_count + TC_2400_count + race * tenure_days,
data = train_data_lm,
method = "lm",
trControl = train_control)
#avg_ABN_processing as outcome
model3 <- train(avg_ABN_processing ~ tenure_days + num_classes + num_subclasses+
ISSUED_applications + au_moves + gender + race +                                   TC_1700_count + TC_1600_count + TC_2100_count + TC_2400_count +
gender * tenure_days + race * tenure_days,
data = train_data_lm,
method = "lm",
trControl = train_control)
summary(model)
